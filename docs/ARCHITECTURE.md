# ğŸ—ï¸ System Architecture

## Overview

The AI-Powered Reconciliation System follows a modular, agent-based architecture inspired by CrewAI patterns. Each agent specializes in a specific task and communicates through structured data flows.

## System Architecture Diagram

```mermaid
graph TB
    subgraph "Input Layer"
        A[old_pricing.xlsx]
        B[new_pricing.xlsx]
        C[trade_metadata.xlsx]
        D[funding_model_reference.xlsx]
    end
    
    subgraph "Agent Layer"
        E[DataLoaderAgent]
        F[ReconAgent]
        G[AnalyzerAgent]
        H[MLDiagnoserAgent]
        I[NarratorAgent]
    end
    
    subgraph "Data Processing"
        J[Merged DataFrame]
        K[Flagged Mismatches]
        L[Rule-based Diagnoses]
        M[ML Predictions]
    end
    
    subgraph "Output Layer"
        N[Excel Report]
        O[Trained ML Model]
        P[Summary Statistics]
    end
    
    A --> E
    B --> E
    C --> E
    D --> E
    E --> J
    J --> F
    F --> K
    K --> G
    G --> L
    L --> H
    H --> M
    M --> I
    I --> N
    I --> P
    H --> O
```

## Data Flow Architecture

### Phase 1: Data Ingestion
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Excel Files â”‚  â”‚ DataLoader  â”‚  â”‚ Merged      â”‚
â”‚ (4 files)   â”‚â”€â–¶â”‚ Agent       â”‚â”€â–¶â”‚ DataFrame   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Phase 2: Mismatch Detection
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Merged      â”‚  â”‚ ReconAgent  â”‚  â”‚ Flagged     â”‚
â”‚ DataFrame   â”‚â”€â–¶â”‚ (Thresholds)â”‚â”€â–¶â”‚ Mismatches  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Phase 3: Analysis & Prediction
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Flagged     â”‚  â”‚ Analyzer    â”‚  â”‚ Rule-based  â”‚
â”‚ Data        â”‚â”€â–¶â”‚ Agent       â”‚â”€â–¶â”‚ Diagnoses   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Training    â”‚  â”‚ MLDiagnoser â”‚  â”‚ ML          â”‚
â”‚ Data        â”‚â”€â–¶â”‚ Agent       â”‚â”€â–¶â”‚ Predictions â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Phase 4: Report Generation
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ All Results â”‚  â”‚ Narrator    â”‚  â”‚ Excel       â”‚
â”‚ (Combined)  â”‚â”€â–¶â”‚ Agent       â”‚â”€â–¶â”‚ Report      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Agent Architecture Details

### DataLoaderAgent
**Purpose**: Data ingestion and preprocessing
**Input**: Multiple Excel files
**Output**: Single merged DataFrame
**Key Methods**:
- `load_all_data()`: Merges all input files on TradeID

### ReconAgent
**Purpose**: Mismatch detection using configurable thresholds
**Input**: Merged DataFrame
**Output**: DataFrame with mismatch flags
**Key Methods**:
- `add_diff_flags(df)`: Adds PV_Mismatch, Delta_Mismatch flags
**Configuration**:
- `pv_tolerance = 1000`
- `delta_tolerance = 0.05`

### AnalyzerAgent
**Purpose**: Rule-based root cause analysis
**Input**: Flagged DataFrame
**Output**: DataFrame with business diagnoses
**Key Methods**:
- `rule_based_diagnosis(row)`: Applies business rules
- `apply(df)`: Processes entire DataFrame

### MLDiagnoserAgent
**Purpose**: Machine learning-based diagnosis prediction
**Input**: Training data (rule-based diagnoses as labels)
**Output**: ML predictions and trained model
**Key Methods**:
- `train(df)`: Trains CatBoost model
- `predict(df)`: Generates ML predictions
- `save_model()`: Persists trained model
- `load_model()`: Loads existing model

### NarratorAgent
**Purpose**: Report generation and summarization
**Input**: Complete DataFrame with all analyses
**Output**: Excel report and summary statistics
**Key Methods**:
- `summarize_report(df)`: Generates summary statistics
- `save_report(df)`: Creates Excel output file

## ML Model Architecture

### Feature Engineering Pipeline

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Feature Engineering                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Numerical Features:                                        â”‚
â”‚ â€¢ PV_old, PV_new (Present Values)                         â”‚
â”‚ â€¢ Delta_old, Delta_new (Risk Measures)                    â”‚
â”‚                                                           â”‚
â”‚ Categorical Features:                                      â”‚
â”‚ â€¢ ProductType (Swap, Option, etc.)                        â”‚
â”‚ â€¢ FundingCurve (USD-LIBOR, SOFR, etc.)                    â”‚
â”‚ â€¢ CSA_Type (Cleared_CSA, Bilateral, etc.)                 â”‚
â”‚ â€¢ ModelVersion (v2024.3, v2024.2, etc.)                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Model Training Process

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Model Training                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1. Feature Preparation                                     â”‚
â”‚    â€¢ Select relevant columns                              â”‚
â”‚    â€¢ Handle missing values                                â”‚
â”‚    â€¢ Encode categorical features                          â”‚
â”‚                                                           â”‚
â”‚ 2. Label Preparation                                      â”‚
â”‚    â€¢ Use rule-based diagnoses as labels                  â”‚
â”‚    â€¢ Encode labels using LabelEncoder                     â”‚
â”‚                                                           â”‚
â”‚ 3. Model Training                                         â”‚
â”‚    â€¢ Initialize CatBoostClassifier                        â”‚
â”‚    â€¢ Specify categorical feature indices                  â”‚
â”‚    â€¢ Fit model to training data                           â”‚
â”‚                                                           â”‚
â”‚ 4. Model Persistence                                      â”‚
â”‚    â€¢ Save model and label encoder                         â”‚
â”‚    â€¢ Store in models/ directory                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Prediction Pipeline

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Prediction Pipeline                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1. Model Loading                                          â”‚
â”‚    â€¢ Load trained CatBoost model                          â”‚
â”‚    â€¢ Load label encoder                                   â”‚
â”‚                                                           â”‚
â”‚ 2. Feature Preparation                                    â”‚
â”‚    â€¢ Apply same preprocessing as training                 â”‚
â”‚    â€¢ Handle new categorical values                        â”‚
â”‚                                                           â”‚
â”‚ 3. Prediction Generation                                  â”‚
â”‚    â€¢ Generate raw predictions                             â”‚
â”‚    â€¢ Decode using label encoder                          â”‚
â”‚                                                           â”‚
â”‚ 4. Result Integration                                     â”‚
â”‚    â€¢ Add ML_Diagnosis column to DataFrame                â”‚
â”‚    â€¢ Compare with rule-based diagnoses                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Data Schema

### Input Data Schema

**old_pricing.xlsx**
| Column | Type | Description |
|--------|------|-------------|
| TradeID | String | Unique trade identifier |
| PV_old | Float | Present value (old model) |
| Delta_old | Float | Delta risk (old model) |

**new_pricing.xlsx**
| Column | Type | Description |
|--------|------|-------------|
| TradeID | String | Unique trade identifier |
| PV_new | Float | Present value (new model) |
| Delta_new | Float | Delta risk (new model) |

**trade_metadata.xlsx**
| Column | Type | Description |
|--------|------|-------------|
| TradeID | String | Unique trade identifier |
| ProductType | String | Financial product type |
| FundingCurve | String | Funding curve identifier |
| CSA_Type | String | Credit Support Annex type |
| ModelVersion | String | Model version identifier |

**funding_model_reference.xlsx**
| Column | Type | Description |
|--------|------|-------------|
| TradeID | String | Unique trade identifier |
| Additional funding-related fields | Various | Funding model parameters |

### Output Data Schema

**final_recon_report.xlsx**
| Column | Type | Description |
|--------|------|-------------|
| TradeID | String | Unique trade identifier |
| PV_old, PV_new | Float | Present values |
| Delta_old, Delta_new | Float | Delta risk measures |
| PV_Diff, Delta_Diff | Float | Differences |
| PV_Mismatch, Delta_Mismatch | Boolean | Mismatch flags |
| ProductType, FundingCurve, CSA_Type, ModelVersion | String | Trade characteristics |
| Diagnosis | String | Rule-based diagnosis |
| ML_Diagnosis | String | ML-based diagnosis |

## Performance Characteristics

### Processing Performance
- **Data Loading**: ~1000 trades/second
- **Mismatch Detection**: ~5000 trades/second
- **Rule-based Analysis**: ~2000 trades/second
- **ML Training**: ~1-5 seconds (depending on data size)
- **ML Prediction**: ~10000 trades/second

### Memory Usage
- **Peak Memory**: ~2x data size (for merged DataFrame)
- **Model Size**: ~1MB (CatBoost model)
- **Report Size**: ~data size + analysis columns

### Scalability
- **Linear Scaling**: Performance scales linearly with data size
- **Memory Efficient**: Processes data in chunks if needed
- **Model Persistence**: Trained model can be reused

## Security Considerations

### Data Security
- **Local Processing**: All data processed locally
- **No External APIs**: No data sent to external services
- **File-based I/O**: Uses standard file operations

### Model Security
- **Model Validation**: Ensures model integrity before loading
- **Version Control**: Model versioning for reproducibility
- **Backup Strategy**: Model backups for disaster recovery

## Error Handling

### Data Validation
- **Missing Values**: Handled gracefully with appropriate defaults
- **Data Type Validation**: Ensures correct data types
- **Schema Validation**: Validates input file structure

### Model Robustness
- **Feature Validation**: Ensures required features are present
- **Prediction Confidence**: Can add confidence scores
- **Fallback Mechanisms**: Rule-based fallback if ML fails

## Monitoring and Logging

### System Monitoring
- **Progress Tracking**: Step-by-step progress indicators
- **Performance Metrics**: Processing time and throughput
- **Error Reporting**: Detailed error messages and stack traces

### Quality Assurance
- **Data Quality Checks**: Validates input data quality
- **Model Performance**: Tracks prediction accuracy
- **Result Validation**: Ensures output consistency

## Deployment Architecture

### Local Deployment
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Local Environment                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ Python 3.8+                                             â”‚
â”‚ â€¢ Required packages (see requirements.txt)                â”‚
â”‚ â€¢ Input data files in data/ directory                     â”‚
â”‚ â€¢ Output reports in project root                          â”‚
â”‚ â€¢ Trained models in models/ directory                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Production Considerations
- **Containerization**: Docker for consistent environments
- **Resource Management**: Memory and CPU optimization
- **Logging**: Structured logging for monitoring
- **Error Handling**: Robust error handling and recovery
- **Performance Tuning**: Optimize for production workloads

## Future Architecture Enhancements

### Microservices Architecture
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Data        â”‚  â”‚ Processing  â”‚  â”‚ ML          â”‚
â”‚ Service     â”‚  â”‚ Service     â”‚  â”‚ Service     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                â”‚                â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚ API Gateway â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Real-time Processing
- **Stream Processing**: Apache Kafka for real-time data
- **Event-driven Architecture**: React to data changes
- **Caching Layer**: Redis for performance optimization

### Cloud Deployment
- **AWS/GCP/Azure**: Cloud-native deployment
- **Auto-scaling**: Handle variable workloads
- **Managed Services**: Use cloud ML services 